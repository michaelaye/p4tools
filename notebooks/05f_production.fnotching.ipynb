{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp production.fnotching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "\n",
    "from p4tools.production import io\n",
    "from p4tools.markings import Blotch,Fan\n",
    "from p4tools.production import markings\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fnotching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def data_to_centers(df, kind, scope=\"hirise\"):\n",
    "    \"\"\"Convert a dataframe with marking data to an array of center coords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.dataframe\n",
    "        Dataframe with either fan or blotch marking data. It probes itself\n",
    "        which one it is by looking at if distances and radii are defined.\n",
    "    kind : {'fan', 'blotch'}\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array with the center coordinates, dimensions: (rows, 2)\n",
    "    \"\"\"\n",
    "    if kind == \"blotch\":\n",
    "        # only the blotch arrays have distance un-defined\n",
    "        Marking = Blotch\n",
    "    else:\n",
    "        Marking = Fan\n",
    "    \n",
    "    return np.vstack([Marking(row, scope=scope).center for _, row in df.iterrows()])\n",
    "\n",
    "#UHM maybe remove that\n",
    "def get_id_from_path(path):\n",
    "    return path.parent.name\n",
    "\n",
    "\n",
    "def get_clusters_in_path(path):\n",
    "    \"\"\"Find csv files in path and combine into DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str, pathlib.Path\n",
    "        Path in where to search for L1A csv files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clusters : list\n",
    "        List with 2 pd.DataFrames\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    id_ = get_id_from_path(path)\n",
    "    for kind in [\"fans\", \"blotches\"]:\n",
    "        try:\n",
    "            df = pd.read_csv(str(path / f\"{id_}_L1A_{kind}.csv\"))\n",
    "        except FileNotFoundError:\n",
    "            df = None\n",
    "        clusters.append(df)\n",
    "    return clusters\n",
    "\n",
    "def remove_opposing_fans(fans, eps=20):\n",
    "    \"\"\"Find fans that have opposite orientation and remove lower voted one.\n",
    "\n",
    "    First check if any fans are close enough to be fnotched (same criteria\n",
    "    as blotch-fan fnotching), then check if any of those have opposite orientation.\n",
    "    Delete the one with lower votes.\n",
    "    If number of votes is equal, take a random choice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fans : pd.DataFrame\n",
    "        Fan marking data\n",
    "    eps : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Data with opposing fans removed.\n",
    "    \"\"\"\n",
    "    distances = pdist(data_to_centers(fans, \"fan\"))\n",
    "    close_indices = np.where(distances < eps)[0]\n",
    "    ind_to_remove = []\n",
    "    for index in close_indices:\n",
    "        fan_indices = calc_indices_from_index(len(distances), index)\n",
    "        # use squeeze to force creation of pd.Series\n",
    "        f1 = fans.iloc[fan_indices[0]].squeeze()\n",
    "        f2 = fans.iloc[fan_indices[1]].squeeze()\n",
    "        angle_diff = f1.angle - f2.angle\n",
    "        # if they differ by between 175 and 185:\n",
    "        if abs(angle_diff - 180) < 5:\n",
    "            if f1.n_votes < f2.n_votes:\n",
    "                ind_to_remove.append(fan_indices[0])\n",
    "            elif f1.n_votes > f2.n_votes:\n",
    "                ind_to_remove.append(fan_indices[1])\n",
    "            else:\n",
    "                ind_to_remove.append(fan_indices[random.randint(0, 1)])\n",
    "    return fans.drop(ind_to_remove)\n",
    "\n",
    "def calc_indices_from_index(n, c):\n",
    "    \"\"\"calculate source indices from condensed distance matrix.\n",
    "\n",
    "    The `pdist` function returns its measurements in a (01, 02, 03, 12, 13...)\n",
    "    fashion and this function can be used to get out the original coordinates\n",
    "    of the 2 inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Length of condensed matrix\n",
    "    c : int\n",
    "        Index of the distance value of interest\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int, int\n",
    "        Coordinate pair of the 2 indices that were used to calculate distance\n",
    "        at index c of the condensed distance matrix.\n",
    "    \"\"\"\n",
    "    n = math.ceil(math.sqrt(2 * n))\n",
    "    ti = np.triu_indices(n, 1)\n",
    "    return ti[0][c], ti[1][c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def fnotch_image_ids(obsid, eps=20, savedir=None, scope=\"hirise\"):\n",
    "    \"Cluster each image_id for an obsid separately.\"\n",
    "    # the clustering results were stored as L1A products\n",
    "    pm = io.PathManager(obsid=obsid, datapath=savedir)\n",
    "    paths = pm.get_obsid_paths(\"L1A\")\n",
    "    if len(paths) == 0:\n",
    "        logger.warning(\"No paths to fnotch found for %s\", obsid)\n",
    "    for path in paths:\n",
    "        id_ = get_id_from_path(path)\n",
    "        pm.id = id_\n",
    "        # make sure the L1B folder exists\n",
    "        pm.reduced_fanfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        fans, blotches = get_clusters_in_path(path)\n",
    "        if fans is not None and len(fans) > 1:\n",
    "            # clean up fans with opposite angles\n",
    "            fans = remove_opposing_fans(fans)\n",
    "        if not any([fans is None, blotches is None]):\n",
    "            logger.debug(\"Fnotching %s\", id_)\n",
    "            distances = cdist(\n",
    "                data_to_centers(fans, \"fan\", scope=scope),\n",
    "                data_to_centers(blotches, \"blotch\", scope=scope),\n",
    "            )\n",
    "            X, Y = np.where(distances < eps)\n",
    "            # X are the indices along the fans input, Y for blotches respectively\n",
    "\n",
    "            # loop over fans and blotches that are within `eps` pixels:\n",
    "            fnotches = []\n",
    "            for fan_loc, blotch_loc in zip(X, Y):\n",
    "                fan = fans.iloc[[fan_loc]]\n",
    "                blotch = blotches.iloc[[blotch_loc]]\n",
    "                fnotches.append(markings.Fnotch(fan, blotch).data)\n",
    "\n",
    "            # store the combined fnotches into one file. The `votes_ratio` is\n",
    "            # stored as well, making it simple to filter/cut on these later for the\n",
    "            # L1C product.\n",
    "            try:\n",
    "                pd.concat(fnotches).to_csv(pm.fnotchfile)\n",
    "            except ValueError as e:\n",
    "                # this is fine, just means notching to fnotch.\n",
    "                if e.args[0].startswith(\"No objects to concatenate\"):\n",
    "                    logger.debug(\"No fnotches found for %s.\", id_)\n",
    "                else:\n",
    "                    # if it's a different error, raise it though:\n",
    "                    raise ValueError\n",
    "\n",
    "            # write out the fans and blotches that where not within fnotching distance:\n",
    "            fans_remaining = fans.loc[list(set(fans.index) - set(X))]\n",
    "            if len(fans_remaining) > 0:\n",
    "                fans_remaining.to_csv(pm.reduced_fanfile, index=False)\n",
    "            blotches_remaining = blotches.loc[list(set(blotches.index) - set(Y))]\n",
    "            if len(blotches_remaining) > 0:\n",
    "                blotches_remaining.to_csv(pm.reduced_blotchfile, index=False)\n",
    "        else:\n",
    "            if blotches is not None:\n",
    "                blotches.to_csv(pm.reduced_blotchfile, index=False)\n",
    "            if fans is not None:\n",
    "                fans.to_csv(pm.reduced_fanfile, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "def write_l1c(kind, slashed, pm):\n",
    "    \"\"\"Write the L1C for marking `kind`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kind : {'fan', 'blotch'}\n",
    "        P4 marking kind\n",
    "    slashed : pd.DataFrame\n",
    "        The remaining fnotch data after applying the cut\n",
    "    pm : io.PathManager\n",
    "        The PathManager for the current image_id\n",
    "    \"\"\"\n",
    "    logger.debug(\"Writing l1c for %s\", kind)\n",
    "    try:\n",
    "        new_kinds = slashed.loc[[kind]].copy()\n",
    "    except KeyError:\n",
    "        logger.debug(\"No %s in slashed dataframe.\", kind)\n",
    "        new_kinds = pd.DataFrame()\n",
    "    l1c = getattr(pm, f\"final_{kind}file\")\n",
    "    l1c.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        # the pathmanager can read the csv files as well:\n",
    "        old_kinds = getattr(pm, f\"reduced_{kind}df\")\n",
    "    except FileNotFoundError:\n",
    "        logger.debug(\"No old %s file.\", kind)\n",
    "        old_kinds = pd.DataFrame()\n",
    "    logger.debug(\"Combining. Writing to %s\", str(l1c))\n",
    "    combined = pd.concat([old_kinds, new_kinds], ignore_index=True, sort=False)\n",
    "    combined.dropna(how=\"all\", axis=1, inplace=True)\n",
    "    if len(combined) > 0:\n",
    "        logger.debug(\"Writing %s\", str(l1c))\n",
    "        combined.to_csv(str(l1c), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "\n",
    "def apply_cut_obsid(obsid, cut=0.5, savedir=None):\n",
    "    pm = io.PathManager(obsid=obsid, cut=cut, datapath=savedir)\n",
    "    try:\n",
    "        fnotches = pm.fnotchdf\n",
    "    except FileNotFoundError:\n",
    "        # no fnotch df was found. Now need to copy over\n",
    "        # standard files to L1C folder\n",
    "        pm.final_blotchfile.parent.mkdir(exist_ok=True)\n",
    "        if pm.reduced_blotchfile.exists():\n",
    "            logger.debug(\"Writing final_blotchfile for %s\", obsid)\n",
    "            pm.reduced_blotchdf.to_csv(pm.final_blotchfile, index=False)\n",
    "        if pm.reduced_fanfile.exists():\n",
    "            logger.debug(\"Writing final_fanfile for %s\", obsid)\n",
    "            pm.reduced_fandf.to_csv(pm.final_fanfile, index=False)\n",
    "    else:\n",
    "        # apply cut\n",
    "        slashed = fnotches[fnotches.vote_ratio > pm.cut]\n",
    "        for kind in [\"fan\", \"blotch\"]:\n",
    "            write_l1c(kind, slashed, pm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def apply_cut(obsid, cut=0.5, savedir=None):\n",
    "    \"\"\"Loop over all image_id paths for an obsid and apply cut to fnotches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obsid : str\n",
    "        HiRISE obsid, i.e. P4 `image_name`\n",
    "    cut : float, 0..1\n",
    "        Value where to cut the vote_ratio of the fnotches.\n",
    "    \"\"\"\n",
    "    pm = io.PathManager(obsid=obsid, cut=cut, datapath=savedir)\n",
    "    paths = pm.get_obsid_paths(\"L1B\")\n",
    "    for path in paths:\n",
    "        id_ = get_id_from_path(path)\n",
    "        logger.debug(\"Slashing %s\", id_)\n",
    "        pm.id = id_\n",
    "        try:\n",
    "            fnotches = pm.fnotchdf\n",
    "        except FileNotFoundError:\n",
    "            # no fnotch df was found. Now need to copy over\n",
    "            # standard files to L1C folder\n",
    "            pm.final_blotchfile.parent.mkdir(exist_ok=True)\n",
    "            if pm.reduced_blotchfile.exists():\n",
    "                logger.debug(\"Writing final_blotchfile for %s\", id_)\n",
    "                pm.reduced_blotchdf.to_csv(pm.final_blotchfile, index=False)\n",
    "            if pm.reduced_fanfile.exists():\n",
    "                logger.debug(\"Writing final_fanfile for %s\", id_)\n",
    "                pm.reduced_fandf.to_csv(pm.final_fanfile, index=False)\n",
    "        else:\n",
    "            # apply cut\n",
    "            slashed = fnotches[fnotches.vote_ratio > pm.cut]\n",
    "            for kind in [\"fan\", \"blotch\"]:\n",
    "                write_l1c(kind, slashed, pm)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
